# coding: utf-8

"""
    Azure Machine Learning - Text Analytics

    The Text Analytics API is a suite of text analytics web services built with Azure Machine Learning.   The API can be used to analyze unstructured text for tasks such as sentiment analysis, key phrase extraction and language detection.   No training data is needed to use this API; just bring your text data.   This API uses advanced natural language processing techniques to deliver best in class predictions.    Further documentation can be found in https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-text-analytics-quick-start

    OpenAPI spec version: 1.0
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""


from pprint import pformat
from six import iteritems
import re


class TopicDetectionInputV2(object):
    """
    NOTE: This class is auto generated by the swagger code generator program.
    Do not edit the class manually.
    """
    def __init__(self, stop_words=None, topics_to_exclude=None, documents=None):
        """
        TopicDetectionInputV2 - a model defined in Swagger

        :param dict swaggerTypes: The key is attribute name
                                  and the value is attribute type.
        :param dict attributeMap: The key is attribute name
                                  and the value is json key in definition.
        """
        self.swagger_types = {
            'stop_words': 'list[str]',
            'topics_to_exclude': 'list[str]',
            'documents': 'list[InputV2]'
        }

        self.attribute_map = {
            'stop_words': 'stopWords',
            'topics_to_exclude': 'topicsToExclude',
            'documents': 'documents'
        }

        self._stop_words = stop_words
        self._topics_to_exclude = topics_to_exclude
        self._documents = documents

    @property
    def stop_words(self):
        """
        Gets the stop_words of this TopicDetectionInputV2.
        List of words to ignore from all documents during pre-processing.

        :return: The stop_words of this TopicDetectionInputV2.
        :rtype: list[str]
        """
        return self._stop_words

    @stop_words.setter
    def stop_words(self, stop_words):
        """
        Sets the stop_words of this TopicDetectionInputV2.
        List of words to ignore from all documents during pre-processing.

        :param stop_words: The stop_words of this TopicDetectionInputV2.
        :type: list[str]
        """

        self._stop_words = stop_words

    @property
    def topics_to_exclude(self):
        """
        Gets the topics_to_exclude of this TopicDetectionInputV2.
        List of topics to omit from the response.

        :return: The topics_to_exclude of this TopicDetectionInputV2.
        :rtype: list[str]
        """
        return self._topics_to_exclude

    @topics_to_exclude.setter
    def topics_to_exclude(self, topics_to_exclude):
        """
        Sets the topics_to_exclude of this TopicDetectionInputV2.
        List of topics to omit from the response.

        :param topics_to_exclude: The topics_to_exclude of this TopicDetectionInputV2.
        :type: list[str]
        """

        self._topics_to_exclude = topics_to_exclude

    @property
    def documents(self):
        """
        Gets the documents of this TopicDetectionInputV2.

        :return: The documents of this TopicDetectionInputV2.
        :rtype: list[InputV2]
        """
        return self._documents

    @documents.setter
    def documents(self, documents):
        """
        Sets the documents of this TopicDetectionInputV2.

        :param documents: The documents of this TopicDetectionInputV2.
        :type: list[InputV2]
        """

        self._documents = documents

    def to_dict(self):
        """
        Returns the model properties as a dict
        """
        result = {}

        for attr, _ in iteritems(self.swagger_types):
            value = getattr(self, attr)
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: x.to_dict() if hasattr(x, "to_dict") else x,
                    value
                ))
            elif hasattr(value, "to_dict"):
                result[attr] = value.to_dict()
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], item[1].to_dict())
                    if hasattr(item[1], "to_dict") else item,
                    value.items()
                ))
            else:
                result[attr] = value

        return result

    def to_str(self):
        """
        Returns the string representation of the model
        """
        return pformat(self.to_dict())

    def __repr__(self):
        """
        For `print` and `pprint`
        """
        return self.to_str()

    def __eq__(self, other):
        """
        Returns true if both objects are equal
        """
        if not isinstance(other, TopicDetectionInputV2):
            return False

        return self.__dict__ == other.__dict__

    def __ne__(self, other):
        """
        Returns true if both objects are not equal
        """
        return not self == other
